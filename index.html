<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" xml:lang="ja" lang="ja"><head><link href="http://gmpg.org/xfn/11" rel="profile"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1"><title>tatsushid.github.io</title><link rel="stylesheet" href="http://fonts.googleapis.com/css?family=PT+Serif:400,400italic,700|PT+Sans:400"><link rel="stylesheet" href="/css/main.css"><script src="/js/highlight.pack.js" async></script><script src="/js/mermaid.min.js" async></script><link rel="apple-touch-icon-precomposed" sizes="144x144" href="/apple-touch-icon-precomposed.png"><link rel="shortcut icon" href="/favicon.ico"><link rel="alternate" type="application/rss+xml" title="RSS" href="http://tatsushid.github.io/index.xml"></head><body class="theme-base-0d layout-reverse sidebar-overlay"><input id="sidebar-checkbox" class="sidebar-checkbox" type="checkbox"><div id="sidebar" class="sidebar"><div class="sidebar-item"><p> </a></p></div><nav class="sidebar-nav"><ul><li><a class="sidebar-nav-item active" href="/">Home</a></li><li><a class="sidebar-nav-item" href="/blog/">Blog</a></li><li><a class="sidebar-nav-item" href="/tags/">Tags</a></li></ul></nav><div class="sidebar-item"><ul class="media-links"><li><a href="https://twitter.com/tatsushi_d"><i class="fa fa-twitter" aria-label="twitter"></i></a></li><li><a href="https://github.com/tatsushid"><i class="fa fa-github" aria-label="github"></i></a></li></ul><div class="footnote">Powered by <a href="http://gohugo.io/">Hugo</a><br>&copy; 2014-2016. Tatsushi Demachi All rights reserved.</div></div></div><div class="wrap"><div class="masthead"><div class="container"><h3 class="masthead-title"><a href="/" title="Home">tatsushid.github.io</a></h3></div></div><div class="container content"><div class="posts"><div class="post"><h1 class="post-title"><a href="/blog/2016/03/tried-udp-load-balancing-added-to-nginx/">NGINX に追加された UDP ロードバランシングを試してみた</a></h1><div class="post-meta">2016-03-19<ul><li><a href="/tags/nginx">NGINX</a></li></ul></div>

<p>つい先日、 NGINX 公式ブログでアナウンスされた <a href="https://www.nginx.com/blog/announcing-udp-load-balancing/">UDP ロードバランシング機能</a>が気になっていたので、まだ正式リリース前ではありますが試してみました。</p>

<h2 id="構成:f07075f6590da3486ce18c8ef1061b72">構成</h2>

<p>UDP で代表的なプロトコルといえば DNS なので、今回は</p>

<div class="mermaid">
graph LR
    Client --- NGINX
    NGINX --- dns1[Dnsmasq1<br>example.com A 127.0.0.10]
    NGINX --- dns2[Dnsmasq2<br>example.com A 127.0.0.20]
</div>

<p>という構成を Docker Compose で作り、 NGINX に対して <code>dig</code> コマンドで <code>example.com</code> の名前解決クエリを送った時に、 <code>127.0.0.10</code> と <code>127.0.0.20</code> が交互に返ってくるかどうかを見ることにしました。この構成を作るに当たって必要なファイルは <a href="https://github.com/tatsushid/nginx-udp-lb-example">Github リポジトリ</a>として公開しています。</p>

<h2 id="準備:f07075f6590da3486ce18c8ef1061b72">準備</h2>

<h3 id="nginx:f07075f6590da3486ce18c8ef1061b72">NGINX</h3>

<p>まず、 UDP ロードバランシング機能が含まれている NGINX を用意する必要がありますが、現時点では開発リポジトリ上にのみ存在する状態のため（ 1.9.13 で正式リリース予定）、 Mercurial 経由で</p>

<pre><code class="language-bash">hg clone http://hg.nginx.org/nginx
</code></pre>

<p>としてソースコードを取得し、</p>

<pre><code class="language-bash">cd nginx
./auto/configure --with-stream
make
make install
</code></pre>

<p>のように <code>--with-stream</code> オプションをつけてコンパイルする必要があります。今回はこれらの一連の NGINX のビルド処理を、 <a href="https://hub.docker.com/_/nginx/">NGINX の Docker 公式リポジトリ</a> の alpine タグの Dockerfile を元に手を加えた <a href="https://github.com/tatsushid/nginx-udp-lb-example/blob/master/Dockerfile">Dockerfile</a> を作り、自動化しています。</p>

<p>NGINX が用意できたところで設定ですが、 UDP のみのロードバランシングの場合非常にシンプルなものになります</p>

<pre><code class="language-nginx">worker_processes  1;

events {
    worker_connections  1024;
}

stream {
    upstream dns_udp_upstreams {
        server ${DNS1_PORT_53_UDP_ADDR}:53;
        server ${DNS2_PORT_53_UDP_ADDR}:53;
    }

    server {
        listen 53 udp;
        proxy_pass dns_udp_upstreams;
        proxy_timeout 1s;
        proxy_responses 1;
    }
}
</code></pre>

<p><code>upstream</code> の設定は通常と同じで、ポイントは <code>server</code> 部ですが、新たに <code>listen</code> ディレクティブに <code>udp</code> が指定できるようになっています。</p>

<p>また、 <code>proxy_responses</code> ディレクティブが追加され、それぞれのクライアント要求において、いくつアップストリームサーバから UDP パケットを受けとったかを数え、 <code>proxy_responses</code> と同じだけパケットを受けとった場合には接続を閉じる、という処理を定義できます。デフォルトは無制限で、その場合、 <code>proxy_timeout</code> の時間が経過するまで UDP パケットの到着を待ち続ける形となるようです。</p>

<h3 id="dnsmasq:f07075f6590da3486ce18c8ef1061b72">Dnsmasq</h3>

<p>実際の DNS リクエストに応答する Dnsmasq は <a href="https://hub.docker.com/r/andyshinn/dnsmasq/">andyshinn/dnsmasq</a> の Docker イメージを使い、二つのサーバの起動オプションにシンプルに <code>--host-record</code> を追加し、</p>

<pre><code class="language-bash">dnsmasq -k --host-record=example.com,127.0.0.10
dnsmasq -k --host-record=example.com,127.0.0.20
</code></pre>

<p>という形でそれぞれ立ち上がるよう設定することとしました。</p>

<h3 id="docker-compose:f07075f6590da3486ce18c8ef1061b72">Docker Compose</h3>

<p>上記の NGINX, Dnsmasq の一連の処理を <a href="https://github.com/tatsushid/nginx-udp-lb-example/blob/master/docker-compose.yml">docker-compose.yml</a> にまとめ、 <code>docker-compose up</code> で環境全体を構築できるようにしています。</p>

<h2 id="動作確認:f07075f6590da3486ce18c8ef1061b72">動作確認</h2>

<p><code>docker-compose up</code> を実行して環境を構築後、 Docker Machine を使っている場合はリクエスト先の IP アドレスを <code>docker-machine ip your-machine</code> で調べておき、下記のようにコマンドを実行すると、交互に結果が返ってくることが確認できるかと思います。</p>

<pre><code class="language-bash">$ dig @192.168.99.100 example.com +short
127.0.0.10
$ dig @192.168.99.100 example.com +short
127.0.0.20
$ dig @192.168.99.100 example.com +short
127.0.0.10
</code></pre>

<h2 id="まとめ:f07075f6590da3486ce18c8ef1061b72">まとめ</h2>

<p>非常にシンプルな設定で UDP ロードバランサが構築できることを確認できました。</p>

<p>これまで UDP ロードバランサを構築しようという場合には、ユーザーモードで動作するロードバランサ、リバースプロキシソフトウェアの選択肢がほぼ存在せず、たとえば Linux においては LVS を用いてのロードバランシングが一般的でした。しかしながら LVS はカーネルモードでの動作を必要とし、昨今隆盛を極めているコンテナ内では使用できないなど、 UDP をベースにしたプロトコルを持つサービスを構築する場合には、物理サーバまたは仮想マシンに頼らざるを得ない状況でした。</p>

<p>今回 NGINX による UDP ロードバランシング機能の提供により、他の TCP, HTTP などのプロトコルと同様に、 UDP もより自由度の高い形でロードバランサを構築することが可能となったことから、今後のサーバ構築時の選択肢を大きく変えていくのではないか、と期待しています</p>
</div><div class="post"><h1 class="post-title"><a href="/blog/2015/12/making-docker-image-of-tinycorelinux/">TinyCoreLinux の Docker イメージを作った話</a></h1><div class="post-meta">2015-12-15<ul><li><a href="/tags/docker">Docker</a></li><li><a href="/tags/nseg">NSEG</a></li></ul></div>

<p>これは <a href="http://www.adventar.org/calendars/808">NSEG Advent Calendar 2015 -Adventar</a> 15 日目の記事です。</p>

<p><a href="/2015/12/packaging-with-docker/">前回</a> に引き続き Docker の話ですが、 <a href="http://www.tinycorelinux.net/">Tiny Core Linux</a> の <a href="https://hub.docker.com/r/tatsushid/tinycore/">Docker イメージ</a>とその仲間（たとえば <a href="https://hub.docker.com/r/tatsushid/tinycore-ruby/">tinycore-ruby</a>）を作った話をまとめておこうと思います。</p>

<h2 id="tiny-core-linux-とは:3b5f7e7f5ab00186906a8ce1b6a9a96c">Tiny Core Linux とは？</h2>

<p><a href="http://www.tinycorelinux.net/">The Core Project</a> で作成されている Linux ディストリビューションの一つで、有名どころでは <a href="https://docs.docker.com/machine/">Docker Machine</a> の OS としても使われていたりします。コア機能に絞り込むと 10MB 以下、 GUI 関連パッケージまで含めても 100MB 以下と、ディスク消費が非常に小さいながらデスクトップ環境まで構築でき、独自形式ながらパッケージ機構も持っているため、他のメジャーなディストリビューションと比べて使用が難しすぎるということもなく、なかなか便利なディストリビューションです。</p>

<h2 id="イメージ作成動機:3b5f7e7f5ab00186906a8ce1b6a9a96c">イメージ作成動機</h2>

<p>Docker をある程度使っていると感じることかと思いますが、公式で提供されている各種ディストリビューションの Docker イメージは容量が少なくとも 200MB 越えしているものがほとんどで、かつ、それを元にした各言語の公式実行環境はそれ以上の容量となることが一般的です。</p>

<p>一方で、特に Node.js などは比較的頻繁にリリースされ、その都度環境を更新することも多くなりますが、その度に大容量のイメージをダウンロード・展開することになります。</p>

<p>そこで、もっとディスク容量を抑えた環境はできないかなと思っていたところ、 Tiny Core Linux の存在を知り、特定の一言語の実行環境であればもっとコンパクトなものが作れるのではないかということで、イメージ作成を試してみることにしました。</p>

<p>結果、基本の OS イメージでは 7MB 弱、先に上げた <a href="https://hub.docker.com/r/tatsushid/tinycore-ruby/">tinycore-ruby</a> イメージでも 60MB そこそこと、一通りの機能を組み込んだ上でもかなり容量を削ることに成功しています。</p>

<h2 id="tiny-core-linux-基本イメージ:3b5f7e7f5ab00186906a8ce1b6a9a96c">Tiny Core Linux 基本イメージ</h2>

<p>各言語の環境を作る前に、まずは基本となる OS イメージが必要なので、それを <a href="http://www.tinycorelinux.net/6.x/x86/release/distribution_files/">x86</a>, <a href="http://www.tinycorelinux.net/6.x/x86_64/release/distribution_files/">x86_64</a> それぞれで配布されている rootfs.gz ないし rootfs64.gz から構築しています。</p>

<p>この rootfs.gz は cpio 形式でアーカイブされていますが、 Docker に読み込ませるには tar 形式である必要があるため、一度これを展開してアーカイブし直す必要があります。</p>

<p>また、 Tiny Core Linux のパッケージは squashfs を利用して作成されており、パッケージインストール時にはこの squashfs をマウントしてファイルを取りだす仕組みになっているため、そのまま rootfs.gz を展開してイメージを作ってしまうと、パッケージ機構を利用する時にはコンテナに privileged 権限をつけて起動する必要が出てきます。これでは日常利用で不便ですので、それを回避するために、 unsquashfs を入れると同時にパッケージプログラムに少々手を加え、 privileged なしでもパッケージを扱えるようにしています</p>

<p>イメージ生成に <a href="https://docs.docker.com/docker-hub/builds/">Docker の Automated Build</a> を使えるようにするため、イメージ作成に必要な処理は <a href="https://github.com/tatsushid/docker-tinycore">Github</a> にて公開していますので、詳しくはそちらを参照してください。</p>

<h2 id="tinycore-ruby-イメージ:3b5f7e7f5ab00186906a8ce1b6a9a96c">tinycore-ruby イメージ</h2>

<p>OS イメージができたので、それを元にして使いたい言語の環境を作るのですが、ここでは Ruby のものを例として見ていきます。</p>

<p>基本的には<a href="https://hub.docker.com/_/ruby/">公式の Ruby イメージ</a>と同じような使い勝手になるよう、公開されている Dockerfile の手順と同様に記述していくことになりますが、元々の目的が容量削減でしたので、一度インストールしたパッケージも動作に必須でなければ極力アンインストールするなどしています。</p>

<p>また、公式でも同様ですが、 <code>RUN</code> の処理を、できるだけ</p>

<pre><code class="language-Dockerfile">RUN gem install bundler --version &quot;$BUNDLER_VERSION&quot; \
    &amp;&amp; bundle config --global path &quot;$GEM_HOME&quot; \
    &amp;&amp; bundle config --global bin &quot;$GEM_HOME/bin&quot;
</code></pre>

<p>のように <code>\ &amp;&amp;</code> でつなげて書いています。これは、同一のシェルコンテキストで実行とするという意味合いもありますが、それぞれを分けて、たとえば</p>

<pre><code class="language-Dockerfile">RUN gem install bundler --version &quot;$BUNDLER_VERSION&quot;
RUN bundle config --global path &quot;$GEM_HOME&quot;
RUN bundle config --global bin &quot;$GEM_HOME/bin&quot;
</code></pre>

<p>のように書くと、それぞれの <code>RUN</code> の処理中で生成されたデータがそのままイメージ容量に加算されていき、後の処理で不要なデータを削除したとしてもイメージ全体のサイズが減らなくなってしまうため、それを回避する目的が主です。同一コンテキスト内で最終的に不要なデータを削除しておけば、その分はイメージ容量には加算されないので、容量肥大化を防ぐことができます。</p>

<p>ただし、このように書いてしまうと、一度イメージ作成処理に失敗すると、次に実行する時もキャッシュが効かず、同一コンテキストの最初から（つまり <code>RUN</code> の最初から）やり直しになってしまい、特に大きなパッケージファイルをダウンロードしている時など実行時間がかかって待たされることになるため、試行錯誤している時などは個別の <code>RUN</code> に分割しておくと、キャッシュの恩恵を受けて効率良く作業ができます。処理が固まったら改めて <code>\ &amp;&amp;</code> でひとまとめにするといいでしょう。</p>

<p>こちらも <a href="https://github.com/tatsushid/docker-tinycore-ruby">Github</a> にてイメージ生成過程は公開してますので、具体的な内容などはそちらを参照してください。</p>

<h2 id="まとめ:3b5f7e7f5ab00186906a8ce1b6a9a96c">まとめ</h2>

<p>以上のような流れで、 Ruby 以外の言語のイメージや、特定のプログラムだけを配置したイメージも比較的簡単に作ることができます。容量だけで見れば公式で配布されている <a href="https://hub.docker.com/_/busybox/">busybox イメージ</a>を使う、という方法もありますが、それだけでは機能不足であるとか、容量は抑えつつ欲しい機能を手軽に追加したい、という向きには、このイメージは便利に使っていただけるかと思います。</p>

<p>余談ですが、現在公開中の <a href="https://hub.docker.com/r/tatsushid/tinycore-ruby/">Ruby</a>, <a href="https://hub.docker.com/r/tatsushid/tinycore-python/">Python</a>, <a href="https://hub.docker.com/r/tatsushid/tinycore-node/">Node.js</a> 以外にも、 PHP, Go などの作成も試してみたのですが、 PHP は TinyCore のパッケージに含まれないライブラリへの依存関係が多く挫折、 Go は作成できたものの公式と容量が 100MB も違いがなく（主に <code>go get</code> などの内部で使われる git, mercurial, subversion を組み込んだ影響）、あえて作る意味もないということで公開はしないこととしました。これらの言語では素直に公式イメージを使うのが吉、ということのようです。</p>
</div><div class="post"><h1 class="post-title"><a href="/blog/2015/12/packaging-with-docker/">Docker を使ってパッケージング</a></h1><div class="post-meta">2015-12-11<ul><li><a href="/tags/docker">Docker</a></li><li><a href="/tags/nseg">NSEG</a></li></ul></div>

<p>これは <a href="http://www.adventar.org/calendars/808">NSEG Advent Calendar 2015 -Adventar</a> 11 日目の記事です。</p>

<h2 id="nseg-とは:ffc6e8e4c2073712378c7d26dc5d3680">NSEG とは？</h2>

<p>一言で言うと「長野の IT 勉強会」ということになりますが、勉強会と言ってもお堅いものではなく、長野県やコンピュータにかかわることを幅広く取り上げて、楽しんだり技術の向上を目指す、といった感じで活動しております。詳しくは <a href="http://nseg.jp/">nseg.jp</a> もご覧ください。</p>

<h2 id="これは何:ffc6e8e4c2073712378c7d26dc5d3680">これは何？</h2>

<p>先日の<a href="https://github.com/nseg-jp/w/wiki/第69回勉強会">「理論から学ぶデータベース実践入門」読書会スペシャル</a>の懇親会で、「 Docker 周辺が盛り上がっているけど、実際業務に使ってたりする？」ということを聞かれたので、自分は「独自で RPM なんかのパッケージを作る時に便利に活用してますよ」ということを話したのですが、じゃあ具体的にどんなことをしているのか、というのを公開している <a href="https://github.com/tatsushid/h2o-rpm">h2o-rpm</a> を元に書いてみようかな、という趣旨です。</p>

<p>Docker 自体はウェブアプリケーションなどの展開・運用にそのまま便利に使え、そちらが本筋とも思いますが、こんな使い方もできる、という一例にしてもらえれば幸いです。なお RPM の SPEC の書き方については、今回は省略します。</p>

<h2 id="パッケージング作業の概要:ffc6e8e4c2073712378c7d26dc5d3680">パッケージング作業の概要</h2>

<p>そもそも RPM などのパッケージを作る時は、パッケージ対象のソースコードと関連ファイル、 SPEC ファイルのようなパッケージング手順が書かれたファイルなどが必要なわけですが、もう一つ、パッケージを作成する対象のディストリビューションのクリーンな環境が必要です。しかしながらこれを毎回物理サーバやいわゆる仮想マシン上でやっていると、メンテナンスが大変、起動に時間がかかる、など作業上のストレスがあっという間にたまることになるので、気軽に作成・削除のできる Docker でその部分をやろう、ということになります。かつての boot2docker や、最近では <a href="https://docs.docker.com/machine/">Docker Machine</a> のおかげで、自分のマシン上でもお手軽に作業ができるのも利点です。</p>

<p>その場合のおおまかなパッケージ作成の流れは、</p>

<ol>
<li>パッケージ作成対象のディストリビューションの環境を整える</li>
<li>パッケージ作成に必要なソースファイルなどを Docker コンテナに展開</li>
<li>ビルド、パッケージングを行う</li>
<li>できたパッケージを Docker コンテナから取り出す</li>
</ol>

<p>となりますが、 <a href="https://github.com/tatsushid/h2o-rpm">h2o-rpm</a> ではこれを <code>Dockerfile</code> と <code>Makefile</code> で記述して、</p>

<ol>
<li><code>Dockerfile</code> を使ったイメージビルドを利用して、環境準備、ソース展開、ビルド、パッケージング</li>
<li>できあがったイメージからデータ取り出しのためだけのダミーコンテナを作ってパッケージを取り出し</li>
</ol>

<p>という形に落とし込んで、 <code>make</code> 一つで自動でパッケージングできるようにしています。パッケージングまでの部分は <code>docker run</code> でやるのも一つなのですが、イメージビルドを使うことにしたのは、</p>

<ul>
<li><code>docker run</code> だと、ローカルファイルシステム・コンテナ間でデータの受け渡し方法を用意するのが面倒</li>
<li>結局自動処理のためにシェルスクリプトを書くことになるのなら、 <code>Dockerfile</code> の方がシンプルで見通しがよい</li>
<li><code>Dockerfile</code> の各ステップの中間イメージが残っていくため、失敗した時の作業再開や調査がやりやすい</li>
</ul>

<p>という理由によるものです。</p>

<p>以下、リポジトリの <code>Dockerfile</code> のうち <a href="https://github.com/tatsushid/h2o-rpm/blob/f167500a687aebb08fccb500c41a903363f94bca/Dockerfile.centos7"><code>Dockerfile.centos7</code></a> と <a href="https://github.com/tatsushid/h2o-rpm/blob/f167500a687aebb08fccb500c41a903363f94bca/Makefile"><code>Makefile</code></a> を元に、この流れを見ていきます。</p>

<h2 id="ビルド環境の準備:ffc6e8e4c2073712378c7d26dc5d3680">ビルド環境の準備</h2>

<p>まず、ビルド環境の準備は <code>Dockerfile</code> に記述してある</p>

<pre><code class="language-Dockerfile">FROM centos:7
ENV HOME /
RUN yum update -y
RUN yum install -y rpm-build redhat-rpm-config rpmdevtools cmake gcc-c++ tar make openssl-devel ruby bison
RUN rpmdev-setuptree
RUN echo '%dist   .el7' &gt;&gt; /.rpmmacros
</code></pre>

<p>で行っています。 <a href="https://hub.docker.com/_/centos/"><code>centos7</code> の公式イメージ</a>を元に、環境内のパッケージの全アップデート、ビルド作業に必要なコンパイラなどのパッケージやビルド対象と依存関係にあるパッケージのインストール、ビルド用ディレクトリツリーの作成などを順に実施しています。</p>

<p><code>ENV HOME /</code> については、 RPM のパッケージング処理がホームディレクトリ配下の <code>rpmbuild</code> ディレクトリを使う、という方式なのと、一般的なコンテナ内ではトップディレクトリが起点になっているというのを合わせる意味で指定しています。イメージ環境自体は使い捨てなので、通常やらないだろう設定をやってもいっこうに構いません。</p>

<h2 id="ソース展開:ffc6e8e4c2073712378c7d26dc5d3680">ソース展開</h2>

<p>ソースの展開は <code>Makefile</code> の</p>

<pre><code class="language-Makefile">cp Dockerfile.$* Dockerfile
tar -czf - Dockerfile rpmbuild | docker build -t $(IMAGE_NAME) -
</code></pre>

<p>と <code>Dockerfile</code> の</p>

<pre><code class="language-Dockerfile">ADD ./rpmbuild/ /rpmbuild/
</code></pre>

<p>の共同作業になります。</p>

<p>まず <code>Makefile</code> の方ですが、各ディストリビューション用に <code>Dockerfile.{dist}</code> のような形でを用意しているものを <code>Dockerfile</code> にコピーした後、パッケージ用ファイルを配置してある <code>rpmbuild</code> ディレクトリとともに <code>tar.gz</code> 形式にまとめ、それを <code>docker build</code> に <code>STDIN</code> 経由で渡しています。このように渡されたファイルは、 <code>tar.gz</code> 内のディレクトリツリー構造そのままに <code>Dockerfile</code> の <code>ADD</code> や <code>COPY</code> で参照できるので、これを使ってコンテナ内の <code>/rpmbuild</code> 以下にファイルを展開しています。</p>

<p>この辺りについては Docker の <a href="https://docs.docker.com/engine/reference/commandline/build/">build コマンドのリファレンス</a>、 <a href="https://docs.docker.com/engine/reference/builder/">Dockerfile のリファレンス</a> に詳しいです。</p>

<p>また、最初にこの方式で書いた時期とは異なり、現在では <code>.dockerignore</code> や <code>docker build</code> の <code>-f</code> オプションも使えますので、上記のような形ではなく、これらの機能を使うことでも同様のものを実現可能と思います。</p>

<h2 id="ビルドとパッケージング:ffc6e8e4c2073712378c7d26dc5d3680">ビルドとパッケージング</h2>

<p>ここは <code>Dockerfile</code> 内の記述になりますが、</p>

<pre><code class="language-Dockerfile">RUN rpmbuild -ba /rpmbuild/SPECS/h2o.spec
RUN tar -czf /tmp/h2o.tar.gz -C /rpmbuild RPMS SRPMS
CMD [&quot;/bin/true&quot;]
</code></pre>

<p>という形で、 RPM のビルド処理を行い、できあがったものを <code>/tmp</code> 以下に <code>tar.gz</code> ファイルとしてまとめています。このアーカイブファイルは次の取り出しで参照します。</p>

<p>最後の <code>CMD</code> 行は、イメージから作成したコンテナを即時終了させるために便宜的に設定したものとなります。</p>

<h2 id="パッケージの取り出し:ffc6e8e4c2073712378c7d26dc5d3680">パッケージの取り出し</h2>

<p>ここは <code>Makefile</code> 側の処理になりますが、前のステップまででできあがったイメージを参照し、</p>

<pre><code class="language-Makefile">docker run --name $(IMAGE_NAME)-tmp $(IMAGE_NAME)
mkdir -p tmp
docker wait $(IMAGE_NAME)-tmp
docker cp $(IMAGE_NAME)-tmp:/tmp/$(TARGZ_FILE) tmp
docker rm $(IMAGE_NAME)-tmp
</code></pre>

<p>のコマンドを順に処理して、 <code>Dockerfile</code> で生成された <code>tar.gz</code> ファイルを取り出しています。</p>

<p>まず <code>docker run</code> で、 <code>Dockerfile</code> で作成したイメージを元にダミーコンテナを起動しています。 <code>Dockerfile</code> 内で指定してある <code>CMD [&quot;/bin/true&quot;]</code> により、このコンテナの実行は即座に終わります。欲しいのはダミーコンテナ内のファイルなので、コンテナが起動している必要はありません。念のため <code>docker wait</code> を入れて、コピー処理の前にコンテナが停止しているのを確実にしています。</p>

<p>ダミーコンテナが停止した後は <code>docker cp</code> を使い、コンテナ内のファイルをローカルのファイルシステムにコピーし、用が済んだダミーコンテナを <code>docker rm</code> で削除しています。</p>

<p>欲しいファイルを取り出せたので、後は好きにこれを展開すればいいのですが、本リポジトリではこれを <code>{dist}.build</code> のようなディレクトリ配下に展開しています。</p>

<h2 id="まとめ:ffc6e8e4c2073712378c7d26dc5d3680">まとめ</h2>

<p>以上のような形で自動パッケージングを行い、ローカル側にコピーしてきているわけですが、もちろんできたものを直接特定のサーバにアップロードするなども自由自在です。対象もパッケージングに限らず、 Docker 環境中でなにかしらの成果物を作り、取り出す、という方法として一般的に使える、と思います。</p>

<p>また、ここでは単に好みから <code>Makefile</code> を使っていますが、シェルスクリプトやバッチファイルでも構いません。かつては <code>tar.gz</code> などのアーカイブファイルを渡さなければいけない以上、 Windows で実行するのは若干難しかったように思いますが、今では前述の <code>.dockerignore</code> や <code>docker build</code> の <code>-f</code> オプションもあるので、敷居は下がったのではないかと思います。</p>

<p>さらに <a href="https://www.microsoft.com/ja-jp/server-cloud/products-windows-server-2016.aspx">Windows Server 2016</a> では Docker がサポートされることも発表されていますので、 Windows アプリケーションも同じような手法でパッケージングできたりするのかもしれず、今後が楽しみです</p>
</div><div class="post"><h1 class="post-title"><a href="/blog/2015/08/docker-machine-env-prevents-macvim-from-opening-window/">docker-machine の env 設定が MacVim と競合する、らしい</a></h1><div class="post-meta">2015-08-31<ul><li><a href="/tags/vim">Vim</a></li><li><a href="/tags/docker">Docker</a></li></ul></div><p>docker-machine を使っている環境上で MacVim を起動すると、なぜか編集ウィンドウが開かない問題に遭遇したので、対応内容をメモ。</p>

<p>結論から言うと、 docker-machine の仮想マシン起動後に設定される各種環境変数（たとえば <code>DOCKER_HOST</code> ）を自動設定するために <code>.bash_profile</code> の中に書いていた</p>

<pre><code class="language-bash">if [ &quot;$(docker-machine status myvm)&quot; = &quot;Running&quot; ]; then
    eval &quot;$(docker-machine env myvm)&quot;
fi
</code></pre>

<p>の部分、特に <code>eval &quot;$(docker-machine env myvm)&quot;</code> が問題を引き起こしており、これを MacVim からの起動時だけ実行しないようにすることで解消した。具体的には、 MacVim から起動した時は <code>TERM</code> 環境変数が <code>dumb</code> となり、通常起動時の値とは異なっていることを利用して</p>

<pre><code class="language-bash">if [ &quot;$TERM&quot; != &quot;dumb&quot; -a &quot;$(docker-machine status myvm)&quot; = &quot;Running&quot; ]; then
    eval &quot;$(docker-machine env myvm)&quot;
fi
</code></pre>

<p>とした。</p>

<p>具体的にこの行がダメな理由についてはよくわからない。 MacVim 自体のソースコードを追った結果、 MacVim は mvim コマンドを開くために内部的にログインシェルを開き、そこからコマンドを起動しているらしく、その流れで <code>.bash_profile</code> が読み込まれて実行されているようだったが、 <code>eval</code> 自体は同じ <code>.bash_profile</code> 中の他の部分でも使用しているので、直接それが問題のようには見えなかった。この辺りは機会があれば調べてみることに。</p>
</div><div class="post"><h1 class="post-title"><a href="/blog/2015/01/managing-libreboard-containers-by-fig/">Fig で Libreboard 環境を構築してみた</a></h1><div class="post-meta">2015-01-18<ul><li><a href="/tags/docker">Docker</a></li><li><a href="/tags/fig">Fig</a></li><li><a href="/tags/libreboard">Libreboard</a></li></ul></div><p><a href="/blog/2015/01/run-libreboard-on-docker/">前回</a> は Docker 上で Libreboard を動かしてみたが、今のところ Libreboard の開発は非常に活発で、更新を Docker コンテナに反映させるたびに長々としたコマンドを叩くのが不便に感じてきたため、 <a href="http://www.fig.sh/">Fig</a> を使って必要なコマンドなどをあらかじめ定義しておき、 <code>fig build</code> や <code>fig up</code> で楽に更新適用ができるようにしてみた。以下はその手順</p>

<ol>
<li>Fig をインストール。今回は手元のサーバが Gentoo だったので emerge で入れてしまったが、 <a href="http://www.fig.sh/install.html">Installing Fig</a> を見る限り、他の環境でも簡単に導入できると思う</li>

<li><p>Fig の作業ディレクトリを適当に作成して移動する</p>

<pre><code>mkdir fig_libreboard
cd fig_libreboard
</code></pre></li>

<li><p><code>fig.yml</code> を作成する。今回は下記のようにしてみた</p>

<pre><code class="language-yaml">libreboard:
  build: ../libreboard
  links:
    - mongo
  ports:
    - &quot;5555:8080&quot;
  environment:
    ROOT_URL: &quot;http://libreboard.example.com&quot;
  command: &quot;sh -c 'export MONGO_URL=mongodb://$MONGO_PORT_27017_TCP_ADDR:$MONGO_PORT_27017_TCP_PORT/libreboard; /meteor-run.sh'&quot;
data:
  image: busybox
  volumes:
    - /data/db
backup:
  image: busybox
  volumes_from:
    - data
mongo:
  image: mongo
  volumes_from:
    - data
  entrypoint: mongod
</code></pre>

<p><code>libreboard</code>, <code>data</code>, <code>backup</code>, <code>mongo</code> の 4 台構成になっている。それぞれの役割は、</p>

<ul>
<li><code>libreboard</code> はアプリケーションを稼働させるコンテナ。先ほど作った <code>fig_libreboard</code> と同一階層の <code>libreboard</code> ディレクトリにある Dockerfile を読み込んで Docker イメージを構築し、それを実行する。データストアとなる MongoDB コンテナとリンクして、起動時に環境変数経由で接続を行っている。</li>
<li><code>data</code> は <a href="https://docs.docker.com/userguide/dockervolumes/">Managing data in containers - Docker Documentation</a> で言うところのデータボリュームコンテナで、 MongoDB のデータを保持するためだけに使われている。</li>
<li><code>mongo</code> は実際に MongoDB が稼働するコンテナ。 <code>data</code> のボリュームに接続してデータをそこに保存している。</li>
<li><code>backup</code> は、 <code>data</code> からは <code>/data/db</code> の中身が見えなかったため、確認作業などのために便宜上作成しておいたコンテナ。これがあると気軽に <code>fig run --rm backup ls -al /data/db</code> などと打って中身を確認したり、 tar でのバックアップ作業がやりやすくなる。が、特別稼働そのものには関係ないので、なくてもかまわない</li>
</ul>

<p>といったところ。起動コマンドやポートの設定は <a href="/blog/2015/01/run-libreboard-on-docker/">前回</a> のものを引き継ぐ形で指定している</p></li>

<li><p>上記設定ができたら、 <code>fig up</code> を実行してコンテナ群を起動する。初回は <code>libreboard</code> コンテナ用のイメージのビルドが実行されるので、少しばかり時間がかかる。無事に起動してウェブブラウザで 5555 番ポートにアクセスしてログイン画面が出れば成功。バックグラウンドでの起動に切り替えたい場合は、いったん <code>Ctrl-c</code> を入力してコンテナ群を停止し、改めて <code>fig up -d</code> で起動すればよい。</p></li>

<li><p>Libreboard の更新があった場合は <code>fig build</code> を実行して Docker イメージを再作成する。イメージ作成に成功したら <code>fig up -d</code> を実行して環境を再起動すればよい</p></li>
</ol>

<p>Fig を使うと、このような感じで一度 <code>fig.yml</code> を書くだけで、機能ごとに分割した複数のコンテナを保持しつつ、日常の操作は簡単な <code>fig</code> コマンドを実行するだけで済むようになる。今回の Libreboard に限らず、 Fig を使うことでホスト側の環境にあれこれ手を入れずとも気軽にウェブアプリケーションの実行環境を用意できるので、単一ホスト内で実行させたいウェブアプリケーションの管理には非常に優れていると思う</p>
</div></div></div></div><label class="sidebar-toggle" for="sidebar-checkbox"></label><script type="text/javascript">
(function(document) {
  var toggle = document.querySelector('.sidebar-toggle');
  var sidebar = document.querySelector('#sidebar');
  var checkbox = document.querySelector('#sidebar-checkbox');

  document.addEventListener('click', function(e) {
    var target = e.target;

    if(!checkbox.checked ||
       sidebar.contains(target) ||
       (target === checkbox || target === toggle)) return;

    checkbox.checked = false;
  }, false);
})(document);
</script></body></html>